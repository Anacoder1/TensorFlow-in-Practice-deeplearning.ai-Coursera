{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exercise 7 - Answer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0dd75dcd-6d19-4b4c-8fc1-aab8044d872a"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-19 14:53:30--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  50.6MB/s    in 1.7s    \n",
            "\n",
            "2019-09-19 14:53:33 (50.6 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0919 14:53:34.349725 140132318586752 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "337c614e-a612-4cf6-a221-55ea55acdb7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b91af769-38fe-4b04-8a2d-c56e088e821b"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0919 14:54:07.261742 140132318586752 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "22d9378b-cfd0-4720-8304-bfdf454e1eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-19 14:54:27--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 2404:6800:4008:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   104MB/s    in 1.4s    \n",
            "\n",
            "2019-09-19 14:54:29 (104 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-09-19 14:54:35--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 2404:6800:4008:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  32.2MB/s    in 0.3s    \n",
            "\n",
            "2019-09-19 14:54:36 (32.2 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "371aad9c-e4bd-4f7e-c1dd-63a15573c1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "56006227-2f42-452c-b42f-b8bb151ae787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "1aa0514c-66f2-4a8a-f915-177b4c6b7539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 36s - loss: 0.1985 - acc: 0.9179 - val_loss: 0.0020 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "100/100 - 30s - loss: 0.0807 - acc: 0.9701 - val_loss: 0.0049 - val_acc: 0.9960\n",
            "Epoch 3/100\n",
            "100/100 - 29s - loss: 0.0478 - acc: 0.9853 - val_loss: 0.0124 - val_acc: 0.9970\n",
            "Epoch 4/100\n",
            "100/100 - 29s - loss: 0.0506 - acc: 0.9858 - val_loss: 0.0439 - val_acc: 0.9919\n",
            "Epoch 5/100\n",
            "100/100 - 29s - loss: 0.0302 - acc: 0.9904 - val_loss: 0.0697 - val_acc: 0.9879\n",
            "Epoch 6/100\n",
            "100/100 - 29s - loss: 0.0358 - acc: 0.9894 - val_loss: 0.0266 - val_acc: 0.9960\n",
            "Epoch 7/100\n",
            "100/100 - 28s - loss: 0.0250 - acc: 0.9919 - val_loss: 0.1082 - val_acc: 0.9858\n",
            "Epoch 8/100\n",
            "100/100 - 28s - loss: 0.0253 - acc: 0.9909 - val_loss: 0.0751 - val_acc: 0.9919\n",
            "Epoch 9/100\n",
            "100/100 - 29s - loss: 0.0447 - acc: 0.9873 - val_loss: 0.0977 - val_acc: 0.9919\n",
            "Epoch 10/100\n",
            "100/100 - 28s - loss: 0.0339 - acc: 0.9889 - val_loss: 0.1931 - val_acc: 0.9838\n",
            "Epoch 11/100\n",
            "100/100 - 29s - loss: 0.0302 - acc: 0.9913 - val_loss: 0.1247 - val_acc: 0.9848\n",
            "Epoch 12/100\n",
            "100/100 - 28s - loss: 0.0195 - acc: 0.9919 - val_loss: 0.3675 - val_acc: 0.9636\n",
            "Epoch 13/100\n",
            "100/100 - 29s - loss: 0.0138 - acc: 0.9965 - val_loss: 0.2381 - val_acc: 0.9798\n",
            "Epoch 14/100\n",
            "100/100 - 27s - loss: 0.0139 - acc: 0.9944 - val_loss: 0.2847 - val_acc: 0.9717\n",
            "Epoch 15/100\n",
            "100/100 - 29s - loss: 0.0124 - acc: 0.9965 - val_loss: 0.1773 - val_acc: 0.9838\n",
            "Epoch 16/100\n",
            "100/100 - 29s - loss: 0.0133 - acc: 0.9964 - val_loss: 0.1700 - val_acc: 0.9919\n",
            "Epoch 17/100\n",
            "100/100 - 28s - loss: 0.0231 - acc: 0.9929 - val_loss: 0.6402 - val_acc: 0.9453\n",
            "Epoch 18/100\n",
            "100/100 - 28s - loss: 0.0139 - acc: 0.9959 - val_loss: 0.1752 - val_acc: 0.9879\n",
            "Epoch 19/100\n",
            "100/100 - 28s - loss: 0.0265 - acc: 0.9924 - val_loss: 0.3441 - val_acc: 0.9727\n",
            "Epoch 20/100\n",
            "100/100 - 28s - loss: 0.0202 - acc: 0.9949 - val_loss: 0.4877 - val_acc: 0.9656\n",
            "Epoch 21/100\n",
            "100/100 - 29s - loss: 0.0357 - acc: 0.9904 - val_loss: 0.4550 - val_acc: 0.9565\n",
            "Epoch 22/100\n",
            "100/100 - 28s - loss: 0.0078 - acc: 0.9975 - val_loss: 0.3202 - val_acc: 0.9798\n",
            "Epoch 23/100\n",
            "100/100 - 28s - loss: 0.0120 - acc: 0.9944 - val_loss: 0.3651 - val_acc: 0.9727\n",
            "Epoch 24/100\n",
            "100/100 - 28s - loss: 0.0044 - acc: 0.9970 - val_loss: 0.7646 - val_acc: 0.9484\n",
            "Epoch 25/100\n",
            "100/100 - 28s - loss: 0.0141 - acc: 0.9954 - val_loss: 0.4851 - val_acc: 0.9656\n",
            "Epoch 26/100\n",
            "100/100 - 28s - loss: 0.0183 - acc: 0.9939 - val_loss: 0.4095 - val_acc: 0.9656\n",
            "Epoch 27/100\n",
            "100/100 - 27s - loss: 0.0132 - acc: 0.9949 - val_loss: 0.6220 - val_acc: 0.9565\n",
            "Epoch 28/100\n",
            "100/100 - 29s - loss: 0.0133 - acc: 0.9954 - val_loss: 0.7477 - val_acc: 0.9575\n",
            "Epoch 29/100\n",
            "100/100 - 29s - loss: 0.0127 - acc: 0.9975 - val_loss: 0.9791 - val_acc: 0.9494\n",
            "Epoch 30/100\n",
            "100/100 - 28s - loss: 0.0098 - acc: 0.9970 - val_loss: 0.3094 - val_acc: 0.9757\n",
            "Epoch 31/100\n",
            "100/100 - 28s - loss: 0.0060 - acc: 0.9980 - val_loss: 0.4514 - val_acc: 0.9696\n",
            "Epoch 32/100\n",
            "100/100 - 28s - loss: 0.0200 - acc: 0.9954 - val_loss: 0.9918 - val_acc: 0.9494\n",
            "Epoch 33/100\n",
            "100/100 - 28s - loss: 0.0123 - acc: 0.9949 - val_loss: 0.7152 - val_acc: 0.9484\n",
            "Epoch 34/100\n",
            "100/100 - 28s - loss: 0.0114 - acc: 0.9960 - val_loss: 0.9609 - val_acc: 0.9474\n",
            "Epoch 35/100\n",
            "100/100 - 28s - loss: 0.0328 - acc: 0.9934 - val_loss: 0.4136 - val_acc: 0.9717\n",
            "Epoch 36/100\n",
            "100/100 - 28s - loss: 0.0303 - acc: 0.9954 - val_loss: 0.6856 - val_acc: 0.9555\n",
            "Epoch 37/100\n",
            "100/100 - 28s - loss: 0.0144 - acc: 0.9970 - val_loss: 0.5446 - val_acc: 0.9686\n",
            "Epoch 38/100\n",
            "100/100 - 28s - loss: 0.0082 - acc: 0.9980 - val_loss: 0.6913 - val_acc: 0.9534\n",
            "Epoch 39/100\n",
            "100/100 - 28s - loss: 0.0197 - acc: 0.9959 - val_loss: 0.5546 - val_acc: 0.9646\n",
            "Epoch 40/100\n",
            "100/100 - 27s - loss: 0.0180 - acc: 0.9949 - val_loss: 0.3065 - val_acc: 0.9798\n",
            "Epoch 41/100\n",
            "100/100 - 29s - loss: 0.0173 - acc: 0.9944 - val_loss: 0.9005 - val_acc: 0.9504\n",
            "Epoch 42/100\n",
            "100/100 - 29s - loss: 0.0042 - acc: 0.9980 - val_loss: 0.7332 - val_acc: 0.9605\n",
            "Epoch 43/100\n",
            "100/100 - 29s - loss: 0.0180 - acc: 0.9965 - val_loss: 0.9710 - val_acc: 0.9474\n",
            "Epoch 44/100\n",
            "100/100 - 27s - loss: 0.0113 - acc: 0.9959 - val_loss: 0.6122 - val_acc: 0.9615\n",
            "Epoch 45/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 28s - loss: 0.0018 - acc: 0.9995 - val_loss: 1.0409 - val_acc: 0.9484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "11651d4c-c3b5-43b5-8d1f-a426f1862a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8mF73C5IIqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}